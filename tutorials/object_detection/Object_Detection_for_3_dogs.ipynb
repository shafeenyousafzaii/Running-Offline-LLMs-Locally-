{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zuLqJw0a94t"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf2if_fGDaWc"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jrmj83afDJrv"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJEzDG6DK2Q"
      },
      "source": [
        "# Train a custom object detection model with MediaPipe Model Maker\n",
        "\n",
        "In this colab notebook, you'll learn how to use [MediaPipe Model Maker](https://developers.google.com/mediapipe/solutions/model_maker) to train a custom object detection model to detect dogs.\n",
        "\n",
        "The Model Maker library uses *transfer learning* to simplify the process of training a TensorFlow Lite model using a custom dataset to use with the [MediaPipe Object Detector task](https://developers.google.com/mediapipe/solutions/vision/object_detector).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYjtwRZGBOI"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "### Install the required packages\n",
        "Start by installing the required packages, including the Model Maker package from the [GitHub repo](https://github.com/google/mediapipe/tree/master/mediapipe/model_maker) and the pycocotools library you'll use for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35BJmtVpAP_n"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install 'keras<3.0.0' mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prQ86DdtD317"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4QQTXHHATDS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "from google.colab import files\n",
        "\n",
        "from mediapipe_model_maker import object_detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6aQvXsD78P"
      },
      "source": [
        "### Prepare the dataset\n",
        "\n",
        "This dataset contains about 130 images of 3 different dogs: a Golden Retriever, a Labrador Retriever mix, and a brindle-colored Formosan Mountain Dog. This is an example image from the dataset.\n",
        "\n",
        "![aci.jpg](https://storage.googleapis.com/tflite-task-tfjs/aci.jpeg)\n",
        "\n",
        "We start with downloading the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AGg7D4JAV62"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/mediapipe-assets/dogs2.zip --no-check-certificate\n",
        "!unzip dogs2.zip\n",
        "train_dataset_path = \"dogs/train\"\n",
        "validation_dataset_path = \"dogs/validate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxh3KInCFeB-"
      },
      "source": [
        "## Train the object detection model\n",
        "\n",
        "### Step 1: Load the dataset\n",
        "\n",
        "* Images in `train_data` is used to train the custom object detection model.\n",
        "* Images in `val_data` is used to check if the model can generalize well to new images that it hasn't seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiAahdsQAdT7"
      },
      "outputs": [],
      "source": [
        "train_data = object_detector.Dataset.from_pascal_voc_folder(\n",
        "    'dogs copy/train',\n",
        "    cache_dir=\"/tmp/od_data/train\",\n",
        ")\n",
        "\n",
        "val_data = object_detector.Dataset.from_pascal_voc_folder(\n",
        "    'dogs copy/validate',\n",
        "    cache_dir=\"/tmp/od_data/validatation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aeDU4mIM4ft"
      },
      "source": [
        "### Step 2: Train the TensorFlow model with the training data.\n",
        "\n",
        "* Set `batch_size = 8` here so you will see that it takes 13 steps to go through the 139 images in the training dataset.\n",
        "* Set `learning_rate = 0.3` here so the model will adjust its weights at a rate of 0.3.\n",
        "* Set `epochs = 50`, which means it will go through the training dataset 50 times. You can look at the validation accuracy during training and stop when you see validation loss (`val_loss`) stop decreasing to avoid overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MClfpsJAfda"
      },
      "outputs": [],
      "source": [
        "hparams = object_detector.HParams(batch_size=8, learning_rate=0.3, epochs=50, export_dir='exported_model')\n",
        "options = object_detector.ObjectDetectorOptions(\n",
        "    supported_model=object_detector.SupportedModels.MOBILENET_V2,\n",
        "    hparams=hparams\n",
        ")\n",
        "model = object_detector.ObjectDetector.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=val_data,\n",
        "    options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4hKeerMmh4"
      },
      "source": [
        "### Step 3. Evaluate the model with the validation data.\n",
        "\n",
        "After training the object detection model using the images in the training dataset, use the 27 images in the validation dataset to evaluate how the model performs against new data it has never seen before.\n",
        "\n",
        "The evaluation metrics are same as [COCO](https://cocodataset.org/#detection-eval)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUqEpcYwAg8L"
      },
      "outputs": [],
      "source": [
        "loss, coco_metrics = model.evaluate(val_data, batch_size=4)\n",
        "print(f\"Validation loss: {loss}\")\n",
        "print(f\"Validation coco metrics: {coco_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARVYk9rGLIl"
      },
      "source": [
        "### Step 4: Export as a TensorFlow Lite model.\n",
        "\n",
        "After creating the model, convert and export it to a Tensorflow Lite model format, and then download it for later use in an on-device application with MediaPipe Tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3eFxoBAiqE"
      },
      "outputs": [],
      "source": [
        "model.export_model('dogs.tflite')\n",
        "!ls exported_model\n",
        "files.download('exported_model/dogs.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
